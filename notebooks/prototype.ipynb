{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from typing import List\n",
    "import sys\n",
    "\n",
    "import spconv\n",
    "from pointnet2.pointnet2_utils import ball_query, gather_operation, furthest_point_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNote: To compute voxel_size, multiply base size (specified in SECOND config) by downsampling ratio.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Note: To compute voxel_size, multiply base size (specified in SECOND config) by downsampling ratio.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PvrcnnConfig:\n",
    "    n_keypoints = 2048\n",
    "    strides = [1, 2, 4, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VSA_MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Represents G in equation 2.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, C_in: int, channels: List):\n",
    "        \"\"\"\n",
    "        C_in: incoming channels.\n",
    "        channels: length-3 list of channels in each layer.\n",
    "        \"\"\"\n",
    "        super(VSA_MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(C_in, channels[0], bias=True),\n",
    "            nn.BatchNorm1d(channels[0]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels[0], channels[1], bias=True),\n",
    "            nn.BatchNorm1d(channels[1]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels[1], channels[2], bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, voxel_set: torch.Tensor):\n",
    "        x = self.layers(voxel_set)\n",
    "        x = x.max(2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class VoxelSetAbstraction(nn.Module):\n",
    "    \"\"\"\n",
    "    For each keypoint, convert its location to\n",
    "    continuous voxel index coordinates. Then fetch\n",
    "    voxels within ball query.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, radius: float, nsample: int, voxel_size: torch.Tensor, volume_offset: torch.Tensor):\n",
    "        \"\"\"\n",
    "        radius: maximum distance for ball query, measured in raw point cloud coordinates.\n",
    "        nsample: maximum number of neighbors to return in ball query.\n",
    "        voxel_size: length-3 tensor describing size of atomic voxel, accounting for stride.\n",
    "        volume_offset: length-3 tensor describing coordinate offset of voxel grid.\n",
    "        \"\"\"\n",
    "        super(VoxelSetAbstraction, self).__init__()\n",
    "        self.radius = radius\n",
    "        self.nsample = nsample\n",
    "        self.voxel_size = voxel_size\n",
    "        self.volume_offset = volume_offset\n",
    "\n",
    "    def to_raw_coordinates(self, voxel_index: torch.Tensor):\n",
    "        \"\"\"\n",
    "        voxel_index: shape (B, Tk, 3) array of coordinates\n",
    "        return: shape (B, Tk, 3) array of locations in raw coordinates.\n",
    "        \"\"\"\n",
    "        location = (voxel_index * self.voxel_size) + self.volume_offset\n",
    "        return location\n",
    "\n",
    "    def get_neighbors(self, keypoint_location: torch.Tensor, voxel_feature: torch.Tensor, voxel_location: torch.Tensor):\n",
    "        neighbor_index = ball_query(self.radius, self.nsample, voxel_location, keypoint_location)\n",
    "        neighbor_feature = gather_operation(voxel_feature, neighbor_index)\n",
    "        neighbor_location = gather_operation(voxel_location, neighbor_index)\n",
    "        return neighbor_feature, neighbor_location\n",
    "\n",
    "    def combine_features(self, neighbor_feature: torch.Tensor, neighbor_location: torch.Tensor, keypoint_location: torch.Tensor):\n",
    "        \"\"\"Form neighborhood feature set (equation 1).\"\"\"\n",
    "        offset_location = neighbor_location - keypoint_location\n",
    "        combined_feature = torch.cat((neighbor_feature, offset_location), dim=2)\n",
    "        return combined_feature\n",
    "\n",
    "    def forward(self, keypoint_location: torch.Tensor, voxel_feature: torch.Tensor, voxel_index: torch.Tensor):\n",
    "        voxel_location = self.to_raw_coordinates(voxel_index)\n",
    "        neighbor_feature, neighbor_location = self.ball_query(keypoint_location, voxel_feature, voxel_location)\n",
    "        feature = self.combine_features(neighbor_feature, neighbor_location, keypoint_location)\n",
    "        return feature\n",
    "\n",
    "\n",
    "class PV_RCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Carry out feature computation described in PV-RCNN paper.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_keypoint: int):\n",
    "        \"\"\"\n",
    "        num_keypoint: number of keypoints\n",
    "        \"\"\"\n",
    "        super(PV_RCNN, self).__init__()\n",
    "        self.num_keypoint = num_keypoint\n",
    "        pass\n",
    "    \n",
    "    def forward(self, raw_point):\n",
    "        keypoint_index = furthest_point_sample(raw_point, self.num_keypoint)\n",
    "        keypoint = gather_operation(raw_point, keypoint_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_3D(nn.Module):\n",
    "    \"\"\"\n",
    "    Placeholder sparse 3D CNN with three blocks:\n",
    "    block_0: [1600, 1200, 41] -> [800, 600, 21]\n",
    "    block_1: [800, 600, 21]   -> [400, 300, 11]\n",
    "    block_2: [400, 300, 11]   -> [200, 150, 5]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, C_in, shape, return_dense=False):\n",
    "        super(CNN_3D, self).__init__()\n",
    "        self.blocks = spconv.SparseSequential(\n",
    "            spconv.SparseConv3d(C_in, 16, 3, 2, padding=1, bias=False),\n",
    "            spconv.SparseConv3d(16, 32, 3, 2, padding=1, bias=False),\n",
    "            spconv.SparseConv3d(32, 64, 3, 2, padding=1, bias=False),\n",
    "        )\n",
    "        self.shape = shape\n",
    "        self.return_dense = return_dense\n",
    "\n",
    "    def forward(self, features, coordinates, batch_size):\n",
    "        coordinates = coors.int()\n",
    "        x0 = spconv.SparseConvTensor(features, coordinates, self.shape, batch_size)\n",
    "        x1 = self.blocks[0](x0)\n",
    "        x2 = self.blocks[1](x1)\n",
    "        x3 = self.blocks[2](x2)\n",
    "        x = [x0, x1, x2, x3]\n",
    "        x = [xi.dense() for xi in x] if self.return_dense else x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = PvrcnnConfig()\n",
    "\n",
    "voxel_size = np.r_[0.05, 0.05, 0.1]\n",
    "grid_bounds = np.r_[0, -40, -3, 70.4, 40, 1]\n",
    "\n",
    "voxel_generator = spconv.utils.VoxelGenerator(\n",
    "    voxel_size=voxel_size, point_cloud_range=grid_bounds,\n",
    "    max_num_points=5, max_voxels=40000,\n",
    ")\n",
    "\n",
    "points = np.fromfile('./sample.bin', dtype=np.float32).reshape(-1, 4)\n",
    "voxels, coords, voxel_population = voxel_generator.generate(points)\n",
    "\n",
    "from_numpy = lambda x: torch.from_numpy(x).unsqueeze(0).cuda()\n",
    "points, voxels, coords, voxel_population = map(\n",
    "    from_numpy, (points, voxels, coords, voxel_population))\n",
    "#indices_keypoint = furthest_point_sample(points, cfg.n_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_3d = CNN_3D(C_in=4, shape=[1600, 1200, 41])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_shape = (grid_bounds[3:] - grid_bounds[:3]) / voxel_size\n",
    "grid_shape = (grid_shape[::-1] + [1, 0, 0]).astype(np.int32) # [1408, 1600, 40] -> [41, 1600, 1408]\n",
    "x_sparse = spconv.SparseConvTensor(voxels, coords, grid_shape, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  41, 1600, 1408], dtype=int32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sparse.spatial_shape\n",
    "\n",
    "#ret = ret.dense()\n",
    "#N, C, D, H, W = ret.shape\n",
    "#ret = ret.view(N, C * D, H, W)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmp",
   "language": "python",
   "name": "tmp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
