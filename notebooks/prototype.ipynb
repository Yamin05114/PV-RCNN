{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import spconv\n",
    "import sys\n",
    "sys.path.append('/home/jhultman/Projects/tmp/PV-RCNN/Pointnet2.PyTorch/')\n",
    "\n",
    "from pointnet2.pointnet2_modules import PointnetSAModuleMSG\n",
    "from pointnet2.pointnet2_utils import furthest_point_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PvrcnnConfig:\n",
    "    C_in = 4\n",
    "    n_keypoints = 2048\n",
    "    strides = [1, 2, 4, 8]\n",
    "    max_num_points = 5\n",
    "    max_voxels = 40000\n",
    "    voxel_size = [0.05, 0.05, 0.1]\n",
    "    grid_bounds = [0, -40, -3, 64, 40, 1]\n",
    "    sample_fpath = './sample.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_3D(nn.Module):\n",
    "    \"\"\"\n",
    "    Placeholder sparse 3D CNN with four blocks:\n",
    "    \n",
    "        block_0: [1600, 1280, 41] -> [1600, 1280, 41]\n",
    "        block_1: [1600, 1280, 41] -> [800, 640, 21]\n",
    "        block_2: [800, 640, 21]   -> [400, 320, 11]\n",
    "        block_3: [400, 320, 11]   -> [200, 160, 6]\n",
    "    \n",
    "    Returns feature volumes strided 1x, 2x, 4x, 8x.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, C_in, grid_shape, cfg):\n",
    "        super(CNN_3D, self).__init__()\n",
    "        self.blocks = spconv.SparseSequential(\n",
    "            spconv.SparseConv3d(C_in, 16, 3, 1, padding=0, bias=False),\n",
    "            spconv.SparseConv3d(16, 16, 3, 2, padding=1, bias=False),\n",
    "            spconv.SparseConv3d(16, 32, 3, 2, padding=1, bias=False),\n",
    "            spconv.SparseConv3d(32, 64, 3, 2, padding=1, bias=False),\n",
    "        )\n",
    "        self.grid_shape = grid_shape\n",
    "        self.base_voxel_size = torch.cuda.FloatTensor(cfg.voxel_size)\n",
    "        self.voxel_offset = torch.cuda.FloatTensor(cfg.grid_bounds[:3])\n",
    "    \n",
    "    def to_global(self, stride, volume):\n",
    "        \"\"\"\n",
    "        Convert integer voxel indices to metric coordinates.\n",
    "        voxel_size: length-3 tensor describing size of atomic voxel, accounting for stride.\n",
    "        voxel_offset: length-3 tensor describing coordinate offset of voxel grid.\n",
    "        \"\"\"\n",
    "        feature, index = volume.features, volume.indices\n",
    "        voxel_size = self.base_voxel_size * (2 ** stride)\n",
    "        xyz = index[..., 1:].float() * voxel_size\n",
    "        xyz = (xyz + self.voxel_offset)\n",
    "        return feature, xyz\n",
    "\n",
    "    def forward(self, features, coordinates, batch_size):\n",
    "        x0 = spconv.SparseConvTensor(\n",
    "            features, coordinates.int(), self.grid_shape, batch_size,\n",
    "        )\n",
    "        x1 = self.blocks[0](x0)\n",
    "        x2 = self.blocks[1](x1)\n",
    "        x3 = self.blocks[2](x2)\n",
    "        x4 = self.blocks[3](x3)\n",
    "        x = [self.to_global(i, x) for i, x in enumerate([x1, x2, x3, x4])]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PV_RCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Carry out feature computation described in PV-RCNN paper.\n",
    "    \n",
    "    For each feature volume stride, convert keypoint locations to\n",
    "    continuous voxel index coordinates. Then fetch voxels within ball query.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cfg):\n",
    "        \"\"\"\n",
    "        num_keypoint: number of keypoints\n",
    "        \"\"\"\n",
    "        super(PV_RCNN, self).__init__()\n",
    "        self.pnet = PointnetSAModuleMSG(\n",
    "            npoint=-1, radii=[0.1, 0.5], nsamples=[16, 32],\n",
    "            mlps=[[16, 32, 64], [16, 32, 128]], use_xyz=True,\n",
    "        )\n",
    "        self.voxel_generator = spconv.utils.VoxelGenerator(\n",
    "            voxel_size=cfg.voxel_size, \n",
    "            point_cloud_range=cfg.grid_bounds,\n",
    "            max_voxels=cfg.max_voxels,\n",
    "            max_num_points=cfg.max_num_points,\n",
    "        )\n",
    "        grid_shape = np.r_[self.voxel_generator.grid_size[::-1]] + [1, 0, 0]\n",
    "        self.cnn = CNN_3D(C_in=cfg.C_in, grid_shape=grid_shape, cfg=cfg)\n",
    "        self.cfg = cfg\n",
    "       \n",
    "    def voxelize(self, points):\n",
    "        \"\"\"\n",
    "        Compute sparse voxel grid.\n",
    "        \"\"\"\n",
    "        features, coordinates, voxel_population = self.voxel_generator.generate(points)\n",
    "        coordinates = np.pad(coordinates, ((0, 0), (1, 0)), mode=\"constant\", constant_values=0)\n",
    "        from_numpy = lambda x: torch.from_numpy(x).cuda()\n",
    "        points, features, coordinates, voxel_population = map(\n",
    "            from_numpy, (points, features, coordinates, voxel_population))\n",
    "        features = features.view(-1, self.cfg.C_in)\n",
    "        return points, features, coordinates, voxel_population\n",
    "    \n",
    "    def forward(self, points):\n",
    "        points, features, coordinates, voxel_population = self.voxelize(points)\n",
    "        out = self.cnn(features, coordinates, batch_size=1)\n",
    "\n",
    "        xyz, point_features = torch.split(points, [3, 1], dim=-1)\n",
    "        out = [(point_features, xyz)] + out\n",
    "\n",
    "        xyz = xyz.unsqueeze(0).contiguous()\n",
    "        indices = furthest_point_sample(xyz, cfg.n_keypoints).squeeze(0).long()\n",
    "        keypoints = points[indices]\n",
    "        keypoints_xyz, keypoints_features = torch.split(keypoints, [3, 1], dim=-1)\n",
    "        voxel_features_i, voxel_coords_i = out[2]\n",
    "\n",
    "        voxel_coords_i = voxel_coords_i.unsqueeze(0).contiguous()\n",
    "        voxel_features_i = voxel_features_i.unsqueeze(0).permute(0, 2, 1).contiguous()\n",
    "        keypoints_xyz = keypoints_xyz.unsqueeze(0).contiguous()\n",
    "\n",
    "        _, out = self.pnet(voxel_coords_i, voxel_features_i, keypoints_xyz)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = PvrcnnConfig()\n",
    "net = PV_RCNN(cfg).cuda()\n",
    "points = np.fromfile(cfg.sample_fpath, dtype=np.float32).reshape(-1, cfg.C_in)\n",
    "out = net(points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmp",
   "language": "python",
   "name": "tmp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
