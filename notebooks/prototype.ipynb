{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from typing import List\n",
    "import sys\n",
    "sys.path.append('/home/jhultman/Projects/tmp/PV-RCNN/Pointnet2.PyTorch/')\n",
    "\n",
    "import spconv\n",
    "from pointnet2.pointnet2_utils import ball_query, gather_operation, furthest_point_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PvrcnnConfig:\n",
    "    C_in = 4\n",
    "    n_keypoints = 2048\n",
    "    strides = [1, 2, 4, 8]\n",
    "    max_num_points = 5\n",
    "    max_voxels = 40000\n",
    "    voxel_size = [0.05, 0.05, 0.1]\n",
    "    grid_bounds = [0, -40, -3, 64, 40, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VSA_MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Represents G in equation 2.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, C_in: int, channels: List):\n",
    "        \"\"\"\n",
    "        C_in: incoming channels.\n",
    "        channels: length-3 list of channels in each layer.\n",
    "        \"\"\"\n",
    "        super(VSA_MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(C_in, channels[0], bias=True),\n",
    "            nn.BatchNorm1d(channels[0]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels[0], channels[1], bias=True),\n",
    "            nn.BatchNorm1d(channels[1]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels[1], channels[2], bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, voxel_set: torch.Tensor):\n",
    "        x = self.layers(voxel_set)\n",
    "        x = x.max(2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class VoxelSetAbstraction(nn.Module):\n",
    "    \"\"\"\n",
    "    For each keypoint, convert its location to\n",
    "    continuous voxel index coordinates. Then fetch\n",
    "    voxels within ball query.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, radius: float, nsample: int, voxel_size: torch.Tensor, volume_offset: torch.Tensor):\n",
    "        \"\"\"\n",
    "        radius: maximum distance for ball query, measured in raw point cloud coordinates.\n",
    "        nsample: maximum number of neighbors to return in ball query.\n",
    "        voxel_size: length-3 tensor describing size of atomic voxel, accounting for stride.\n",
    "        volume_offset: length-3 tensor describing coordinate offset of voxel grid.\n",
    "        \"\"\"\n",
    "        super(VoxelSetAbstraction, self).__init__()\n",
    "        self.radius = radius\n",
    "        self.nsample = nsample\n",
    "        self.voxel_size = voxel_size\n",
    "        self.volume_offset = volume_offset\n",
    "\n",
    "    def to_raw_coordinates(self, voxel_index: torch.Tensor):\n",
    "        \"\"\"\n",
    "        voxel_index: shape (B, Tk, 3) array of coordinates\n",
    "        return: shape (B, Tk, 3) array of locations in raw coordinates.\n",
    "        \"\"\"\n",
    "        location = (voxel_index * self.voxel_size) + self.volume_offset\n",
    "        return location\n",
    "\n",
    "    def get_neighbors(self, keypoint_location: torch.Tensor, voxel_feature: torch.Tensor, voxel_location: torch.Tensor):\n",
    "        neighbor_index = ball_query(self.radius, self.nsample, voxel_location, keypoint_location)\n",
    "        neighbor_feature = gather_operation(voxel_feature, neighbor_index)\n",
    "        neighbor_location = gather_operation(voxel_location, neighbor_index)\n",
    "        return neighbor_feature, neighbor_location\n",
    "\n",
    "    def combine_features(self, neighbor_feature: torch.Tensor, neighbor_location: torch.Tensor, keypoint_location: torch.Tensor):\n",
    "        \"\"\"Form neighborhood feature set (equation 1).\"\"\"\n",
    "        offset_location = neighbor_location - keypoint_location\n",
    "        combined_feature = torch.cat((neighbor_feature, offset_location), dim=2)\n",
    "        return combined_feature\n",
    "\n",
    "    def forward(self, keypoint_location: torch.Tensor, voxel_feature: torch.Tensor, voxel_index: torch.Tensor):\n",
    "        voxel_location = self.to_raw_coordinates(voxel_index)\n",
    "        neighbor_feature, neighbor_location = self.ball_query(keypoint_location, voxel_feature, voxel_location)\n",
    "        feature = self.combine_features(neighbor_feature, neighbor_location, keypoint_location)\n",
    "        return feature\n",
    "\n",
    "\n",
    "class PV_RCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Carry out feature computation described in PV-RCNN paper.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_keypoint: int):\n",
    "        \"\"\"\n",
    "        num_keypoint: number of keypoints\n",
    "        \"\"\"\n",
    "        super(PV_RCNN, self).__init__()\n",
    "        self.num_keypoint = num_keypoint\n",
    "        pass\n",
    "    \n",
    "    def forward(self, raw_point):\n",
    "        keypoint_index = furthest_point_sample(raw_point, self.num_keypoint)\n",
    "        keypoint = gather_operation(raw_point, keypoint_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_3D(nn.Module):\n",
    "    \"\"\"\n",
    "    Placeholder sparse 3D CNN with three blocks:\n",
    "        block_0: [1600, 1280, 41] -> [800, 640, 21]\n",
    "        block_1: [800, 640, 21]   -> [400, 320, 11]\n",
    "        block_2: [400, 320, 11]   -> [200, 160, 6]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, C_in, shape):\n",
    "        super(CNN_3D, self).__init__()\n",
    "        self.blocks = spconv.SparseSequential(\n",
    "            spconv.SparseConv3d(C_in, 16, 3, 2, padding=1, bias=False),\n",
    "            spconv.SparseConv3d(16, 32, 3, 2, padding=1, bias=False),\n",
    "            spconv.SparseConv3d(32, 64, 3, 2, padding=1, bias=False),\n",
    "        )\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, features, coordinates, batch_size):\n",
    "        x0 = spconv.SparseConvTensor(\n",
    "            features, coordinates.int(), self.shape, batch_size,\n",
    "        )\n",
    "        x1 = self.blocks[0](x0)\n",
    "        x2 = self.blocks[1](x1)\n",
    "        x3 = self.blocks[2](x2)\n",
    "        x = [x0, x1, x2, x3]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = PvrcnnConfig()\n",
    "\n",
    "voxel_generator = spconv.utils.VoxelGenerator(\n",
    "    voxel_size=cfg.voxel_size, \n",
    "    point_cloud_range=cfg.grid_bounds,\n",
    "    max_voxels=cfg.max_voxels,\n",
    "    max_num_points=cfg.max_num_points,\n",
    ")\n",
    "\n",
    "points = np.fromfile('./sample.bin', dtype=np.float32).reshape(-1, cfg.C_in)\n",
    "features, coordinates, voxel_population = voxel_generator.generate(points)\n",
    "coordinates = np.pad(coordinates, ((0, 0), (1, 0)), mode=\"constant\", constant_values=0)\n",
    "\n",
    "from_numpy = lambda x: torch.from_numpy(x).cuda()\n",
    "points, features, coordinates, voxel_population = map(\n",
    "    from_numpy, (points, features, coordinates, voxel_population))\n",
    "features = features.view(-1, cfg.C_in)\n",
    "\n",
    "shape = np.r_[voxel_generator.grid_size[::-1]] + [1, 0, 0] # [1280, 1600, 40] -> [41, 1600, 1280]\n",
    "cnn_3d = CNN_3D(C_in=cfg.C_in, shape=shape).cuda()\n",
    "out = cnn_3d(features.view(-1, 4), coordinates, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_keypoint = furthest_point_sample(points, cfg.n_keypoints)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmp",
   "language": "python",
   "name": "tmp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
